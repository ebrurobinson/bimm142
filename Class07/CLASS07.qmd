---
title: "Class07:Machine Learning1"
author: "Ebru Robinson"
format: pdf
---

Today we will begin our exploration of some "classical" machine learning approches. We will start with clustering:

Let's first make up some data to cluster where we know what the answer should be.

```{r}
hist(rnorm(10))
```





```{r}
x <- c(rnorm(30,mean=-3),rnorm(30,mean=3))
y <- rev(x)

x <- cbind(x,y)
head(x)
```
 a wee peak at 
```{r}
plot(x)
```
 
 then main functiion in "base" R for k-means clustering is called `kmeans()`.
```{r}
k <- kmeans(x, centers=4)
k
```
>Q. How big are the clusters(i.e their size)?

```{r}
k$size
```
 
 >Q. What clusters do my data points reside in?
 
```{r}
k$cluster
```
 
 >Q, Make a plot of our data colored by cluster assignment- i.e. make a result figure...
 
```{r}
plot(x, col=k$cluster)
points(k$centers,centers=4,col="blue", pch=15)
```
```{r}
k4 <- kmeans(x,centers=4)
plot(x, col=k$cluster)
points(k$centers,centers=4,col="blue", pch=15)
```
 
 >Q. Run kmeans with values center(i.e values of k) equal 1 to 6
 
```{r}
k1 <- kmeans(x,centers=1)$tot.withinss
k2 <- kmeans(x,centers=2)$tot.withinss
k3 <- kmeans(x,centers=3)$tot.withinss
k4 <- kmeans(x,centers=4)$tot.withinss
k5 <- kmeans(x,centers=5)$tot.withinss
k6 <- kmeans(x,centers=6)$tot.withinss
ans <- c(k1,k2,k3,k4,k5,k6)
```
 or use a for loop
 
```{r}
ans <- NULL
for(i in 1:6) {
  ans <- c(ans, kmeans(x,centers=i)$tot.withinss)
}
ans
```
 Make a "scree-plot"
```{r}
plot(ans, typ="b")
```
 
 
##Hierarchical Clustering

The main function in "base" R for this is called `hclust()`

```{r}
d <- dist(x)
hc <- hclust(d)
hc
```

```{r}
plot(hc)
abline(h=7, col="red")
```
 to obtain clusters from our `hclust` result object **hc** we "cut" the tree to yield different sub branches. For this we use the `cutree()` function
```{r}
grps <- cutree(hc,h=7)
grps
```
 Results figure
```{r}
plot(x,col=grps)
```

```{r}
#install.packages("pheatmap")
```

```{r}
library("pheatmap")

```







## Principal Component Analysis (PCA)
```{r}
url <- "https://tinyurl.com/UK-foods"
x <- read.csv(url)
```


>Q1. How many rows and columns are in your new data frame named x? What R functions could you use to answer this questions?

This will return both the number of rows and columns in the data frame x.

```{r}
dim(x)
```
```{r}
## Preview the first 6 rows
head(x)
```
```{r}
# Note how the minus indexing works
rownames(x) <- x[,1]
x <- x[,-1]
head(x)
```
```{r}
x <- read.csv(url, row.names = 1)
head(x)
```

>Q2. Which approach to solving the ‘row-names problem’ mentioned above do you prefer and why? Is one approach more robust than another under certain circumstances?

I like fixing it up front when reading the data...

I prefer the import-time approach: set row names when you read the file, e.g. read.csv(url, row.names = 1). It is more robust and reproducible.

##spotting major differences and trends

```{r}
# Using base R
barplot(as.matrix(x), beside=T, col=rainbow(nrow(x)))
```

 ## Pairs plots and heatmaps
 Scatterplot matrices ("pairs plots") can be useful for relatively small datasets like this one. lets have a look:
```{r}
pairs(x, col=rainbow(nrow(x)), pch=16)
```
```{r}
library(pheatmap)

pheatmap( as.matrix(x) )
```
>Q6. Based on the pairs and heatmap figures, which countries cluster together and what does this suggest about their food consumption patterns? Can you easily tell what the main differences between N. Ireland and the other countries of the UK in terms of this data-set?
 
 It looks like Wales and England are quite similar in their consumption of these foods. It is still quite diffucult to tell what is going on in the dataset
 
 
 ##PCA to the rescue
 
 The main function in "base" R for PCA is called `prcomp()`.
 
 As we want to do PCA on the food data for the different countries we will want the foods in the columns
 
```{r}
# Use the prcomp() PCA function 
pca <- prcomp(t(x))
summary(pca)
```
 
Our result object is csalled `pca` and it has a `$x` component that will look at first
```{r}
library(ggplot2)

# Convert PCA results to a data frame
df <- as.data.frame(pca$x)
df$Country <- rownames(df)

# Define colors in the same order as your countries appear in df
cols <- c("orange", "red", "blue", "darkgreen")
names(cols) <- df$Country   # optional: name colors explicitly for safety

# Plot
ggplot(df, aes(x = PC1, y = PC2, label = Country, color = Country)) +
  geom_point(size = 3) +
  geom_text(vjust = -0.5) +
  scale_color_manual(values = cols) +
  xlab("PC1") +
  ylab("PC2") +
  theme_bw()

```
Another major result out of PCA is the so-called "variable" loadings or `$rotation` that tells us how the original variables (foods) contributes to the PC's (our new axis)


```{r}
ggplot(pca$rotation) +aes(PC1, rownames(pca$rotation))+ geom_col()
```

